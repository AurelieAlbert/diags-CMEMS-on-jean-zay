{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selection of EN4 profiles to compare to a simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this script the EN4 database is browsed in order to find the profiles that will be compare to the outputs of one simulation. \n",
    "\n",
    "The comparison will not be a simple colocation of the profile inside the model grid but we want to make a statistical comparison of the observed profile with  a significant number of profiles close to it in the model (close in terms of space and time, for instance in a 0,5째 radius around the profile location and 10 days before and after it has been sampled)\n",
    "\n",
    "Therefor the selected profiles must have to be relevant according to some criteria :\n",
    "  - they must be inside the domain of simulation (the mask file of the configuration file must be provided)  \n",
    "  - they must be sampled inside the period of simulation (the period shortened by a certain amount of days must be provided)\n",
    "  - they must go as deep as a given depth (according to the desired depth for the comparison profiles)\n",
    "  - they must be in a location where there are enough model profiles (for instance if profile is too close to an island or the coast)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criteria of profiles selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# depth of the desired comparison profile in m\n",
    "depthmin=1000\n",
    "# radius of the circle around the profile location in which we take the modeled profiles, in 째  \n",
    "radius_max=0.25\n",
    "# period of time around the profile sampling date in which we take the modeled profiles, in days\n",
    "period=5\n",
    "# minimum amount of model profiles to be considered to make a significant statistical comparison, for instance in a 1째 square and 30-days window we have 2.6 millions modeled profiles, in a 0.5째x10 days 216 000\n",
    "number_of_model_profiles=100000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# location and name of the maskfile of the model configuration\n",
    "meshfile='/gpfsstore/rech/egi/commun/MEDWEST60/MEDWEST60-I/mesh_mask.nc'\n",
    "# period of the simulation (year,month,day)\n",
    "ymin=2010;mmin=1;dmin=1\n",
    "ymax=2010;mmax=9;dmax=30\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### imports of librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import dask\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import glob as glob\n",
    "import time\n",
    "from datetime import date\n",
    "import io\n",
    "import json\n",
    "import seawater\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### determining the dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2010-01-06\n",
      "2010-01-07\n",
      "2010-01-08\n",
      "2010-01-09\n",
      "2010-01-10\n",
      "2010-01-11\n",
      "2010-01-12\n",
      "2010-01-13\n",
      "2010-01-14\n",
      "2010-01-15\n",
      "2010-01-16\n",
      "2010-01-17\n",
      "2010-01-18\n",
      "2010-01-19\n",
      "2010-01-20\n",
      "2010-01-21\n",
      "2010-01-22\n",
      "2010-01-23\n",
      "2010-01-24\n",
      "2010-01-25\n",
      "2010-01-26\n",
      "2010-01-27\n",
      "2010-01-28\n",
      "2010-01-29\n",
      "2010-01-30\n",
      "2010-01-31\n",
      "2010-02-01\n",
      "2010-02-02\n",
      "2010-02-03\n",
      "2010-02-04\n",
      "2010-02-05\n",
      "2010-02-06\n",
      "2010-02-07\n",
      "2010-02-08\n",
      "2010-02-09\n",
      "2010-02-10\n",
      "2010-02-11\n",
      "2010-02-12\n",
      "2010-02-13\n",
      "2010-02-14\n",
      "2010-02-15\n",
      "2010-02-16\n",
      "2010-02-17\n",
      "2010-02-18\n",
      "2010-02-19\n",
      "2010-02-20\n",
      "2010-02-21\n",
      "2010-02-22\n",
      "2010-02-23\n",
      "2010-02-24\n",
      "2010-02-25\n",
      "2010-02-26\n",
      "2010-02-27\n",
      "2010-02-28\n",
      "2010-03-01\n",
      "2010-03-02\n",
      "2010-03-03\n",
      "2010-03-04\n",
      "2010-03-05\n",
      "2010-03-06\n",
      "2010-03-07\n",
      "2010-03-08\n",
      "2010-03-09\n",
      "2010-03-10\n",
      "2010-03-11\n",
      "2010-03-12\n",
      "2010-03-13\n",
      "2010-03-14\n",
      "2010-03-15\n",
      "2010-03-16\n",
      "2010-03-17\n",
      "2010-03-18\n",
      "2010-03-19\n",
      "2010-03-20\n",
      "2010-03-21\n",
      "2010-03-22\n",
      "2010-03-23\n",
      "2010-03-24\n",
      "2010-03-25\n",
      "2010-03-26\n",
      "2010-03-27\n",
      "2010-03-28\n",
      "2010-03-29\n",
      "2010-03-30\n",
      "2010-03-31\n",
      "2010-04-01\n",
      "2010-04-02\n",
      "2010-04-03\n",
      "2010-04-04\n",
      "2010-04-05\n",
      "2010-04-06\n",
      "2010-04-07\n",
      "2010-04-08\n",
      "2010-04-09\n",
      "2010-04-10\n",
      "2010-04-11\n",
      "2010-04-12\n",
      "2010-04-13\n",
      "2010-04-14\n",
      "2010-04-15\n",
      "2010-04-16\n",
      "2010-04-17\n",
      "2010-04-18\n",
      "2010-04-19\n",
      "2010-04-20\n",
      "2010-04-21\n",
      "2010-04-22\n",
      "2010-04-23\n",
      "2010-04-24\n",
      "2010-04-25\n",
      "2010-04-26\n",
      "2010-04-27\n",
      "2010-04-28\n",
      "2010-04-29\n",
      "2010-04-30\n",
      "2010-05-01\n",
      "2010-05-02\n",
      "2010-05-03\n",
      "2010-05-04\n",
      "2010-05-05\n",
      "2010-05-06\n",
      "2010-05-07\n",
      "2010-05-08\n",
      "2010-05-09\n",
      "2010-05-10\n",
      "2010-05-11\n",
      "2010-05-12\n",
      "2010-05-13\n",
      "2010-05-14\n",
      "2010-05-15\n",
      "2010-05-16\n",
      "2010-05-17\n",
      "2010-05-18\n",
      "2010-05-19\n",
      "2010-05-20\n",
      "2010-05-21\n",
      "2010-05-22\n",
      "2010-05-23\n",
      "2010-05-24\n",
      "2010-05-25\n",
      "2010-05-26\n",
      "2010-05-27\n",
      "2010-05-28\n",
      "2010-05-29\n",
      "2010-05-30\n",
      "2010-05-31\n",
      "2010-06-01\n",
      "2010-06-02\n",
      "2010-06-03\n",
      "2010-06-04\n",
      "2010-06-05\n",
      "2010-06-06\n",
      "2010-06-07\n",
      "2010-06-08\n",
      "2010-06-09\n",
      "2010-06-10\n",
      "2010-06-11\n",
      "2010-06-12\n",
      "2010-06-13\n",
      "2010-06-14\n",
      "2010-06-15\n",
      "2010-06-16\n",
      "2010-06-17\n",
      "2010-06-18\n",
      "2010-06-19\n",
      "2010-06-20\n",
      "2010-06-21\n",
      "2010-06-22\n",
      "2010-06-23\n",
      "2010-06-24\n",
      "2010-06-25\n",
      "2010-06-26\n",
      "2010-06-27\n",
      "2010-06-28\n",
      "2010-06-29\n",
      "2010-06-30\n",
      "2010-07-01\n",
      "2010-07-02\n",
      "2010-07-03\n",
      "2010-07-04\n",
      "2010-07-05\n",
      "2010-07-06\n",
      "2010-07-07\n",
      "2010-07-08\n",
      "2010-07-09\n",
      "2010-07-10\n",
      "2010-07-11\n",
      "2010-07-12\n",
      "2010-07-13\n",
      "2010-07-14\n",
      "2010-07-15\n",
      "2010-07-16\n",
      "2010-07-17\n",
      "2010-07-18\n",
      "2010-07-19\n",
      "2010-07-20\n",
      "2010-07-21\n",
      "2010-07-22\n",
      "2010-07-23\n",
      "2010-07-24\n",
      "2010-07-25\n",
      "2010-07-26\n",
      "2010-07-27\n",
      "2010-07-28\n",
      "2010-07-29\n",
      "2010-07-30\n",
      "2010-07-31\n",
      "2010-08-01\n",
      "2010-08-02\n",
      "2010-08-03\n",
      "2010-08-04\n",
      "2010-08-05\n",
      "2010-08-06\n",
      "2010-08-07\n",
      "2010-08-08\n",
      "2010-08-09\n",
      "2010-08-10\n",
      "2010-08-11\n",
      "2010-08-12\n",
      "2010-08-13\n",
      "2010-08-14\n",
      "2010-08-15\n",
      "2010-08-16\n",
      "2010-08-17\n",
      "2010-08-18\n",
      "2010-08-19\n",
      "2010-08-20\n",
      "2010-08-21\n",
      "2010-08-22\n",
      "2010-08-23\n",
      "2010-08-24\n",
      "2010-08-25\n",
      "2010-08-26\n",
      "2010-08-27\n",
      "2010-08-28\n",
      "2010-08-29\n",
      "2010-08-30\n",
      "2010-08-31\n",
      "2010-09-01\n",
      "2010-09-02\n",
      "2010-09-03\n",
      "2010-09-04\n",
      "2010-09-05\n",
      "2010-09-06\n",
      "2010-09-07\n",
      "2010-09-08\n",
      "2010-09-09\n",
      "2010-09-10\n",
      "2010-09-11\n",
      "2010-09-12\n",
      "2010-09-13\n",
      "2010-09-14\n",
      "2010-09-15\n",
      "2010-09-16\n",
      "2010-09-17\n",
      "2010-09-18\n",
      "2010-09-19\n",
      "2010-09-20\n",
      "2010-09-21\n",
      "2010-09-22\n",
      "2010-09-23\n",
      "2010-09-24\n",
      "2010-09-25\n"
     ]
    }
   ],
   "source": [
    "datemin=datetime.date(ymin,mmin,dmin)\n",
    "datemax=datetime.date(ymax,mmax,dmax)\n",
    "# list of days between datemin and datemax\n",
    "def date_range(start, end, period):\n",
    "    r = (end+datetime.timedelta(days=1)-start).days\n",
    "    return [start+datetime.timedelta(days=i) for i in range(period,r-period)]\n",
    "dateList = date_range(datemin, datemax,period) \n",
    "for date in dateList:\n",
    "    print(date)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List of all EN4 files to search in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['20100106_prof.nc', '20100107_prof.nc', '20100108_prof.nc', '20100109_prof.nc', '20100110_prof.nc', '20100111_prof.nc', '20100112_prof.nc', '20100113_prof.nc', '20100114_prof.nc', '20100115_prof.nc', '20100116_prof.nc', '20100117_prof.nc', '20100118_prof.nc', '20100119_prof.nc', '20100120_prof.nc', '20100121_prof.nc', '20100122_prof.nc', '20100123_prof.nc', '20100124_prof.nc', '20100125_prof.nc', '20100126_prof.nc', '20100127_prof.nc', '20100128_prof.nc', '20100129_prof.nc', '20100130_prof.nc', '20100131_prof.nc', '20100201_prof.nc', '20100202_prof.nc', '20100203_prof.nc', '20100204_prof.nc', '20100205_prof.nc', '20100206_prof.nc', '20100207_prof.nc', '20100208_prof.nc', '20100209_prof.nc', '20100210_prof.nc', '20100211_prof.nc', '20100212_prof.nc', '20100213_prof.nc', '20100214_prof.nc', '20100215_prof.nc', '20100216_prof.nc', '20100217_prof.nc', '20100218_prof.nc', '20100219_prof.nc', '20100220_prof.nc', '20100221_prof.nc', '20100222_prof.nc', '20100223_prof.nc', '20100224_prof.nc', '20100225_prof.nc', '20100226_prof.nc', '20100227_prof.nc', '20100228_prof.nc', '20100301_prof.nc', '20100302_prof.nc', '20100303_prof.nc', '20100304_prof.nc', '20100305_prof.nc', '20100306_prof.nc', '20100307_prof.nc', '20100308_prof.nc', '20100309_prof.nc', '20100310_prof.nc', '20100311_prof.nc', '20100312_prof.nc', '20100313_prof.nc', '20100314_prof.nc', '20100315_prof.nc', '20100316_prof.nc', '20100317_prof.nc', '20100318_prof.nc', '20100319_prof.nc', '20100320_prof.nc', '20100321_prof.nc', '20100322_prof.nc', '20100323_prof.nc', '20100324_prof.nc', '20100325_prof.nc', '20100326_prof.nc', '20100327_prof.nc', '20100328_prof.nc', '20100329_prof.nc', '20100330_prof.nc', '20100331_prof.nc', '20100401_prof.nc', '20100402_prof.nc', '20100403_prof.nc', '20100404_prof.nc', '20100405_prof.nc', '20100406_prof.nc', '20100407_prof.nc', '20100408_prof.nc', '20100409_prof.nc', '20100410_prof.nc', '20100411_prof.nc', '20100412_prof.nc', '20100413_prof.nc', '20100414_prof.nc', '20100415_prof.nc', '20100416_prof.nc', '20100417_prof.nc', '20100418_prof.nc', '20100419_prof.nc', '20100420_prof.nc', '20100421_prof.nc', '20100422_prof.nc', '20100423_prof.nc', '20100424_prof.nc', '20100425_prof.nc', '20100426_prof.nc', '20100427_prof.nc', '20100428_prof.nc', '20100429_prof.nc', '20100430_prof.nc', '20100501_prof.nc', '20100502_prof.nc', '20100503_prof.nc', '20100504_prof.nc', '20100505_prof.nc', '20100506_prof.nc', '20100507_prof.nc', '20100508_prof.nc', '20100509_prof.nc', '20100510_prof.nc', '20100511_prof.nc', '20100512_prof.nc', '20100513_prof.nc', '20100514_prof.nc', '20100515_prof.nc', '20100516_prof.nc', '20100517_prof.nc', '20100518_prof.nc', '20100519_prof.nc', '20100520_prof.nc', '20100521_prof.nc', '20100522_prof.nc', '20100523_prof.nc', '20100524_prof.nc', '20100525_prof.nc', '20100526_prof.nc', '20100527_prof.nc', '20100528_prof.nc', '20100529_prof.nc', '20100530_prof.nc', '20100531_prof.nc', '20100601_prof.nc', '20100602_prof.nc', '20100603_prof.nc', '20100604_prof.nc', '20100605_prof.nc', '20100606_prof.nc', '20100607_prof.nc', '20100608_prof.nc', '20100609_prof.nc', '20100610_prof.nc', '20100611_prof.nc', '20100612_prof.nc', '20100613_prof.nc', '20100614_prof.nc', '20100615_prof.nc', '20100616_prof.nc', '20100617_prof.nc', '20100618_prof.nc', '20100619_prof.nc', '20100620_prof.nc', '20100621_prof.nc', '20100622_prof.nc', '20100623_prof.nc', '20100624_prof.nc', '20100625_prof.nc', '20100626_prof.nc', '20100627_prof.nc', '20100628_prof.nc', '20100629_prof.nc', '20100630_prof.nc', '20100701_prof.nc', '20100702_prof.nc', '20100703_prof.nc', '20100704_prof.nc', '20100705_prof.nc', '20100706_prof.nc', '20100707_prof.nc', '20100708_prof.nc', '20100709_prof.nc', '20100710_prof.nc', '20100711_prof.nc', '20100712_prof.nc', '20100713_prof.nc', '20100714_prof.nc', '20100715_prof.nc', '20100716_prof.nc', '20100717_prof.nc', '20100718_prof.nc', '20100719_prof.nc', '20100720_prof.nc', '20100721_prof.nc', '20100722_prof.nc', '20100723_prof.nc', '20100724_prof.nc', '20100725_prof.nc', '20100726_prof.nc', '20100727_prof.nc', '20100728_prof.nc', '20100729_prof.nc', '20100730_prof.nc', '20100731_prof.nc', '20100801_prof.nc', '20100802_prof.nc', '20100803_prof.nc', '20100804_prof.nc', '20100805_prof.nc', '20100806_prof.nc', '20100807_prof.nc', '20100808_prof.nc', '20100809_prof.nc', '20100810_prof.nc', '20100811_prof.nc', '20100812_prof.nc', '20100813_prof.nc', '20100814_prof.nc', '20100815_prof.nc', '20100816_prof.nc', '20100817_prof.nc', '20100818_prof.nc', '20100819_prof.nc', '20100820_prof.nc', '20100821_prof.nc', '20100822_prof.nc', '20100823_prof.nc', '20100824_prof.nc', '20100825_prof.nc', '20100826_prof.nc', '20100827_prof.nc', '20100828_prof.nc', '20100829_prof.nc', '20100830_prof.nc', '20100831_prof.nc', '20100901_prof.nc', '20100902_prof.nc', '20100903_prof.nc', '20100904_prof.nc', '20100905_prof.nc', '20100906_prof.nc', '20100907_prof.nc', '20100908_prof.nc', '20100909_prof.nc', '20100910_prof.nc', '20100911_prof.nc', '20100912_prof.nc', '20100913_prof.nc', '20100914_prof.nc', '20100915_prof.nc', '20100916_prof.nc', '20100917_prof.nc', '20100918_prof.nc', '20100919_prof.nc', '20100920_prof.nc', '20100921_prof.nc', '20100922_prof.nc', '20100923_prof.nc', '20100924_prof.nc', '20100925_prof.nc']\n"
     ]
    }
   ],
   "source": [
    "diren4=\"/gpfswork/rech/egi/rote001/EN4/\"\n",
    "list_filesEN4=[]\n",
    "for date in dateList:\n",
    "    year=date.year\n",
    "    month=date.month\n",
    "    day=date.day\n",
    "    mm=\"{:02d}\".format(month) #month on 2 digits\n",
    "    dd=\"{:02d}\".format(day) # day on 2 digits\n",
    "    list_filesEN4.append(str(year)+str(mm)+str(dd)+'_prof.nc')\n",
    "print(list_filesEN4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the criteria for one profile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Localisation of the profile location inside model domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "    prof=71\n",
    "    fileEN4=list_filesEN4[0]\n",
    "    # open the maskfile and get lat lon and mask\n",
    "    ds=xr.open_dataset(meshfile)\n",
    "    lat=ds.nav_lat\n",
    "    lon=ds.nav_lon\n",
    "    latmin,latmax,lonmin,lonmax=(lat.min(),lat.max(),lon.min(),lon.max())\n",
    "    tmask=ds.tmask    \n",
    "    #open the profile file and read the infos on latitude, longitude and date \n",
    "    tfileEN4=diren4+fileEN4\n",
    "    dsen4=xr.open_dataset(tfileEN4)\n",
    "    laten4=dsen4['LATITUDE'][prof].values\n",
    "    lonen4=dsen4['LONGITUDE'][prof].values\n",
    "    \n",
    "    i0,j0=600,436\n",
    "       \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check if profile location is on land"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check if profile is in the ocean : \n"
     ]
    }
   ],
   "source": [
    "    print('check if profile is in the ocean : ')\n",
    "    dsN=xr.open_dataset(meshfile)\n",
    "    tmaskN=dsN.tmask\n",
    "    if tmaskN[0,0,int(j0)-1,int(i0)-1] == 1:\n",
    "        check=0\n",
    "    else:\n",
    "        check=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(check)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### check depth of profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check if profile has a good depth : \n",
      "profile max depth is 1959.4314 m\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "    print('check if profile has a good depth : ')\n",
    "    #open the profile file and read the infos on pressure and latitude\n",
    "    tfileEN4=diren4+fileEN4\n",
    "    dsen4=xr.open_dataset(tfileEN4)\n",
    "    presen4=dsen4['PRES_ADJUSTED'][prof].values\n",
    "    laten4=dsen4['LATITUDE'][prof].values\n",
    "    #convert pressure to depth\n",
    "    depthen4=seawater.dpth(presen4,laten4)\n",
    "    #look for the last level\n",
    "    indzprof=np.min(np.where(np.isnan(depthen4)==True))\n",
    "    dmax=depthen4[indzprof-1]\n",
    "    print('profile max depth is '+str(dmax)+' m')\n",
    "    if dmax >= depthmin:\n",
    "        check=0\n",
    "    else:\n",
    "        check=1\n",
    "    print(check)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### check if there are enough model profiles around the obs profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check if there are enough model profiles : \n"
     ]
    }
   ],
   "source": [
    "    print('check if there are enough model profiles : ')\n",
    "    #open mask file and read lat, lon and mask\n",
    "    ds=xr.open_dataset(meshfile)\n",
    "    gdpts=np.int(np.round(radius_max*60))\n",
    "    lat=ds.nav_lat[j0-gdpts:j0+gdpts,i0-gdpts:i0+gdpts]\n",
    "    lon=ds.nav_lon[j0-gdpts:j0+gdpts,i0-gdpts:i0+gdpts]\n",
    "    depth=ds.gdept_1d[0]\n",
    "    tmask=ds.tmask[0,:,j0-gdpts:j0+gdpts,i0-gdpts:i0+gdpts]\n",
    "    # Stack the variables\n",
    "    lon_stacked = lon.stack(profile=('x', 'y'))\n",
    "    lat_stacked = lat.stack(profile=('x', 'y'))\n",
    "    mask_stacked = tmask.stack(profile=('x', 'y'))\n",
    "    #Get the depth at every grid point\n",
    "    d,ly,lx=tmask.shape\n",
    "    depthmod2d=np.zeros([lx,ly])\n",
    "    for j in np.arange(ly):\n",
    "        for i in np.arange(lx):\n",
    "            depthmod2d[j,i]=depth[np.min(np.where(tmask[:,j,i].values<1))].values\n",
    "    xr_depthmod2d=xr.DataArray(depthmod2d, dims=(\"x\", \"y\"))    \n",
    "    depth_stacked = xr_depthmod2d.stack(profile=('x', 'y'))\n",
    "    #open the profile file and read the infos on latitude, longitude\n",
    "    tfileEN4=diren4+fileEN4\n",
    "    dsen4=xr.open_dataset(tfileEN4)\n",
    "    laten4=dsen4['LATITUDE'][prof].values\n",
    "    lonen4=dsen4['LONGITUDE'][prof].values\n",
    "    #find the profiles filling criteria\n",
    "    distance_threshold = radius_max\n",
    "    square_distance_to_observation = (lon_stacked - lonen4)**2 + (lat_stacked-laten4)**2\n",
    "    is_close_to_observation = (square_distance_to_observation < distance_threshold) & (depth_stacked > depthmin)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.DataArray (profile: 900)>\n",
      "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "...\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "Coordinates:\n",
      "  * profile  (profile) MultiIndex\n",
      "  - x        (profile) int64 0 0 0 0 0 0 0 0 0 0 ... 29 29 29 29 29 29 29 29 29\n",
      "  - y        (profile) int64 0 1 2 3 4 5 6 7 8 9 ... 21 22 23 24 25 26 27 28 29\n"
     ]
    }
   ],
   "source": [
    "print(1*is_close_to_observation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "    nb_profiles=np.sum(1*is_close_to_observation)*24*(period*2+1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.DataArray ()>\n",
      "array(237600)\n"
     ]
    }
   ],
   "source": [
    "print(nb_profiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### function to select one profile and save its characteristics in the json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dict(fileEN4,prof,i0,j0,dictyml):\n",
    "    print('Adding profile to the dict')\n",
    "    #open the profile file and read the infos on latitude, longitude\n",
    "    tfileEN4=diren4+fileEN4\n",
    "    dsen4=xr.open_dataset(tfileEN4)\n",
    "    laten4=dsen4['LATITUDE'][prof].values\n",
    "    lonen4=dsen4['LONGITUDE'][prof].values\n",
    "    dayen4=dsen4['JULD'][prof].values\n",
    "    if dictyml:\n",
    "        up={'Profile_'+str(fileEN4)+'_'+str(prof):{'reference':'Profile_'+str(fileEN4)+'_'+str(prof),\n",
    "                                                        'file':fileEN4,'profile no':int(prof),\n",
    "                                                        'latitude':float(laten4),\n",
    "                                                        'longitude':float(lonen4),\n",
    "                                                        'date':str(dayen4),\n",
    "                                                        'i0':int(i0),'j0':int(j0)}}\n",
    "        dictyml.update(up)\n",
    "    else:\n",
    "        dictyml={'Profile_'+str(fileEN4)+'_'+str(prof):{'reference':'Profile_'+str(fileEN4)+'_'+str(prof),\n",
    "                                                        'file':fileEN4,'profile no':int(prof),\n",
    "                                                        'latitude':float(laten4),\n",
    "                                                        'longitude':float(lonen4),\n",
    "                                                        'date':str(dayen4),\n",
    "                                                        'i0':int(i0),'j0':int(j0)}}\n",
    "    return dictyml\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#loop on all the files\n",
    "\n",
    "jdict={}\n",
    "for f in range(len(list_filesEN4)):\n",
    "    fileEN4=list_filesEN4[f]\n",
    "    ds=xr.open_dataset(diren4+fileEN4)\n",
    "    nprof=len(ds.N_PROF)\n",
    "    for prof in range(nprof):\n",
    "        i0,j0=loc(fileEN4,prof)\n",
    "        if (i0,j0) == (-1,-1):\n",
    "            print('profile is not in the domain at all')\n",
    "            continue\n",
    "        check=check_prof_in_ocean(i0,j0)\n",
    "        if check == 1:\n",
    "            print('no, profile is on the land')\n",
    "            continue\n",
    "        print('yes, profile is in the ocean')\n",
    "        check=check_prof_depth(fileEN4,prof)\n",
    "        if check == 1:\n",
    "            print('no, profile is not deep enough')\n",
    "            continue\n",
    "        print('yes, profile is deep enough')\n",
    "        check_number_profile(fileEN4,prof,i0,j0)\n",
    "        print(check)\n",
    "        if check == 1:\n",
    "            print('no, there are not enough model profiles')\n",
    "            continue\n",
    "        print('yes, there are enough model profiles')\n",
    "        jdict=make_dict(fileEN4,prof,i0,j0,jdict)\n",
    "    \n",
    "#write dict in a json file           \n",
    "# name of the json file in which selection of profiles informations will be stored\n",
    "jsonfile='txt/MEDWEST60-BLBT02_'+str(datemin)+'-'+str(datemax)+'_'+str(depthmin)+'m_'+str(radius_max)+'x'+str(period)+'d_'+str(number_of_model_profiles)+'.json'\n",
    "with io.open(str(jsonfile), 'a+', encoding='utf8') as outfile:\n",
    "    outfile.write(str(json.dumps(jdict, sort_keys=True,indent=4, separators=(',', ': '))))\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
