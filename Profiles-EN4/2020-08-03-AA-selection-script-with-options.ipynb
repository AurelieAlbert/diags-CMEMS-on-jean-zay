{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selection of EN4 profiles to compare to a simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this script the EN4 database is browsed in order to find the profiles that will be compare to the outputs of one simulation. \n",
    "\n",
    "The comparison will not be a simple colocation of the profile inside the model grid but we want to make a statistical comparison of the observed profile with  a significant number of profiles close to it in the model (close in terms of space and time, for instance in a 0,5° radius around the profile location and 10 days before and after it has been sampled)\n",
    "\n",
    "Therefor the selected profiles must have to be relevant according to some criteria :\n",
    "  - they must be inside the domain of simulation (the mask file of the configuration file must be provided)  \n",
    "  - they must be sampled inside the period of simulation (the period shortened by a certain amount of days must be provided)\n",
    "  - they must go as deep as a given depth (according to the desired depth for the comparison profiles)\n",
    "  - they must be in a location where there are enough model profiles (for instance if profile is too close to an island or the coast)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criteria of profiles selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# period of the simulation (year,month,day)\n",
    "ymin=2010;mmin=1;dmin=1\n",
    "ymax=2010;mmax=9;dmax=30\n",
    "# depth of the desired comparison profile in m\n",
    "depthmin=1000\n",
    "# radius of the circle around the profile location in which we take the modeled profiles, in °  \n",
    "radius_max=0.25\n",
    "# period of time around the profile sampling date in which we take the modeled profiles, in days\n",
    "period=5\n",
    "# minimum amount of model profiles to be considered to make a significant statistical comparison, for instance in a 1° square and 30-days window we have 2.6 millions modeled profiles, in a 0.5°x10 days 216 000\n",
    "number_of_model_profiles=100000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# location and name of the maskfile of the model configuration\n",
    "meshfile='/gpfsstore/rech/egi/commun/MEDWEST60/MEDWEST60-I/mesh_mask.nc'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### imports of librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import dask\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import glob as glob\n",
    "import time\n",
    "from datetime import date\n",
    "import io\n",
    "import json\n",
    "import seawater\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### determining the dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "datemin=datetime.date(ymin,mmin,dmin)\n",
    "datemax=datetime.date(ymax,mmax,dmax)\n",
    "# list of days between datemin and datemax\n",
    "def date_range(start, end, period):\n",
    "    r = (end+datetime.timedelta(days=1)-start).days\n",
    "    return [start+datetime.timedelta(days=i) for i in range(period,r-period)]\n",
    "dateList = date_range(datemin, datemax,period) \n",
    "for date in dateList:\n",
    "    print(date)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List of all EN4 files to search in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "diren4=\"/gpfswork/rech/egi/rote001/EN4/\"\n",
    "list_filesEN4=[]\n",
    "for date in dateList:\n",
    "    year=date.year\n",
    "    month=date.month\n",
    "    day=date.day\n",
    "    mm=\"{:02d}\".format(month) #month on 2 digits\n",
    "    dd=\"{:02d}\".format(day) # day on 2 digits\n",
    "    list_filesEN4.append(str(year)+str(mm)+str(dd)+'_prof.nc')\n",
    "print(list_filesEN4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the criteria for one profile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Localisation of the profile location inside model domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loc(fileEN4,prof):\n",
    "    # open the maskfile and get lat lon and mask\n",
    "    ds=xr.open_dataset(meshfile)\n",
    "    lat=ds.nav_lat\n",
    "    lon=ds.nav_lon\n",
    "    latmin,latmax,lonmin,lonmax=(lat.min(),lat.max(),lon.min(),lon.max())\n",
    "    tmask=ds.tmask    \n",
    "    #open the profile file and read the infos on latitude, longitude and date \n",
    "    tfileEN4=diren4+fileEN4\n",
    "    dsen4=xr.open_dataset(tfileEN4)\n",
    "    laten4=dsen4['LATITUDE'][prof].values\n",
    "    lonen4=dsen4['LONGITUDE'][prof].values\n",
    "    \n",
    "    if (lonmin.values<lonen4)&(lonen4<lonmax.values)&(latmin.values<laten4)&(laten4<latmax.values):\n",
    "            with open('txt/prof0.txt','w') as txt_file:\n",
    "                txt_file.write('Profile_'+str(fileEN4)+'_'+str(prof)+' '+str(lonen4)+' '+str(laten4))\n",
    "            if os.path.exists('ij_found.out'):\n",
    "                !rm ij_found.out\n",
    "            \n",
    "            !/gpfswork/rech/egi/rote001/git/sosie/bin/ij_from_lon_lat.x -i $meshfile -p txt/prof0.txt > txt/output\n",
    "\n",
    "            with open('ij_found.out','r') as txt_file:\n",
    "                last_line = txt_file.readlines()[-1]\n",
    "                if last_line[1] == '#':\n",
    "                    print('Profile no '+str(prof)+' in file '+str(fileEN4)+' is not in the domain, do not keep')\n",
    "                    i0,j0=-1,-1\n",
    "                else:\n",
    "                    print('Profile no '+str(prof)+' in file '+str(fileEN4)+' is in the domain, go proceed')\n",
    "                    i0=int(last_line.split()[1])\n",
    "                    j0=int(last_line.split()[2])\n",
    "    else:\n",
    "        print('Profile no '+str(prof)+' in file '+str(fileEN4)+' is not in the domain, do not keep')\n",
    "#        print('Profile coordinates are '+str(lonen4)+'°E x '+str(laten4)+'°N')\n",
    "#        print('Model domain is '+str(latmin.values)+'-'+str(latmax.values)+'°E x '+str(lonmin.values)+'-'+str(lonmax.values)+'°N')\n",
    "        i0,j0=-1,-1\n",
    "       \n",
    "    return i0,j0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check if profile location is on land"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_prof_in_ocean(i0,j0):\n",
    "    print('check if profile is in the ocean : ')\n",
    "    dsN=xr.open_dataset(meshfile)\n",
    "    tmaskN=dsN.tmask\n",
    "    if tmaskN[0,0,int(j0)-1,int(i0)-1] == 1:\n",
    "        check=0\n",
    "    else:\n",
    "        check=1\n",
    "    return check\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### check depth of profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_prof_depth(fileEN4,prof):\n",
    "    print('check if profile has a good depth : ')\n",
    "    #open the profile file and read the infos on pressure and latitude\n",
    "    tfileEN4=diren4+fileEN4\n",
    "    dsen4=xr.open_dataset(tfileEN4)\n",
    "    presen4=dsen4['PRES_ADJUSTED'][prof].values\n",
    "    laten4=dsen4['LATITUDE'][prof].values\n",
    "    #convert pressure to depth\n",
    "    depthen4=seawater.dpth(presen4,laten4)\n",
    "    #look for the last level\n",
    "    indzprof=np.min(np.where(np.isnan(depthen4)==True))\n",
    "    dmax=depthen4[indzprof-1]\n",
    "    print('profile max depth is '+str(dmax)+' m')\n",
    "    if dmax >= depthmin:\n",
    "        check=0\n",
    "    else:\n",
    "        check=1\n",
    "    return check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### check if there are enough model profiles around the obs profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "def map_profile_from_jsonfile(lon,lat,radius,lonmin, lonmax, latmin, latmax):\n",
    "    fig=plt.figure(figsize=(20,15))\n",
    "    ax = plt.subplot(111,projection=ccrs.PlateCarree(central_longitude=0))\n",
    "    ax.set_extent((lonmin, lonmax, latmin, latmax))\n",
    "    ax.coastlines(resolution=\"10m\")\n",
    "    gl = ax.gridlines(draw_labels=True, linestyle=':', color='black',\n",
    "                      alpha=0.5)\n",
    "    gl.xlabels_top = False\n",
    "    gl.ylabels_right = False\n",
    "    gl.xformatter = LONGITUDE_FORMATTER\n",
    "    gl.yformatter = LATITUDE_FORMATTER\n",
    "    ax.tick_params('both',labelsize=22)\n",
    "    ax.add_patch(mpatches.Circle(xy=[lon,lat], radius=radius, color='green', alpha=0.3, transform=ccrs.PlateCarree(), zorder=30))\n",
    "    plt.scatter(lon,lat, c='g', linewidth='0', s=18);\n",
    "\n",
    "def check_number_profile(fileEN4,prof,i0,j0,dmap=0):\n",
    "    print('check if there are enough model profiles : ')\n",
    "    #open mask file and read lat, lon and mask\n",
    "    ds=xr.open_dataset(meshfile)\n",
    "    gdpts=np.int(np.round(radius_max*60))\n",
    "    lat=ds.nav_lat[j0-gdpts:j0+gdpts,i0-gdpts:i0+gdpts]\n",
    "    lon=ds.nav_lon[j0-gdpts:j0+gdpts,i0-gdpts:i0+gdpts]\n",
    "    depth=ds.gdept_1d[0]\n",
    "    tmask=ds.tmask[0,:,j0-gdpts:j0+gdpts,i0-gdpts:i0+gdpts]\n",
    "    # Stack the variables\n",
    "    lon_stacked = lon.stack(profile=('x', 'y'))\n",
    "    lat_stacked = lat.stack(profile=('x', 'y'))\n",
    "    mask_stacked = tmask.stack(profile=('x', 'y'))\n",
    "    #Get the depth at every grid point\n",
    "    d,ly,lx=tmask.shape\n",
    "    depthmod2d=np.zeros([lx,ly])\n",
    "    for j in np.arange(ly):\n",
    "        for i in np.arange(lx):\n",
    "            depthmod2d[j,i]=depth[np.min(np.where(tmask[:,j,i].values<1))].values\n",
    "    xr_depthmod2d=xr.DataArray(depthmod2d, dims=(\"y\", \"x\"))    \n",
    "    depth_stacked = xr_depthmod2d.stack(profile=('x', 'y'))\n",
    "    #open the profile file and read the infos on latitude, longitude\n",
    "    tfileEN4=diren4+fileEN4\n",
    "    dsen4=xr.open_dataset(tfileEN4)\n",
    "    laten4=dsen4['LATITUDE'][prof].values\n",
    "    lonen4=dsen4['LONGITUDE'][prof].values\n",
    "    #find the profiles filling criteria\n",
    "    distance_threshold = radius_max\n",
    "    square_distance_to_observation = (lon_stacked - lonen4)**2 + (lat_stacked-laten4)**2\n",
    "    is_close_to_observation = (square_distance_to_observation < distance_threshold) & (depth_stacked > depthmin)\n",
    "    nb_profiles=np.sum(1*is_close_to_observation)*24*(period*2+1)\n",
    "    print('There is a total of '+str(nb_profiles)+' model oceanic profiles with enough depth')\n",
    "    if dmap == 1:\n",
    "        map_profile_from_jsonfile(lonen4,laten4,radius_max,lonmin, lonmax, latmin, latmax)\n",
    "    if nb_profiles > number_of_model_profiles:\n",
    "        check=0\n",
    "    else:\n",
    "        check=1\n",
    "    return check\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### function to select one profile and save its characteristics in the json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dict(fileEN4,prof,i0,j0,dictyml):\n",
    "    print('Adding profile to the dict')\n",
    "    #open the profile file and read the infos on latitude, longitude\n",
    "    tfileEN4=diren4+fileEN4\n",
    "    dsen4=xr.open_dataset(tfileEN4)\n",
    "    laten4=dsen4['LATITUDE'][prof].values\n",
    "    lonen4=dsen4['LONGITUDE'][prof].values\n",
    "    dayen4=dsen4['JULD'][prof].values\n",
    "    if dictyml:\n",
    "        up={'Profile_'+str(fileEN4)+'_'+str(prof):{'reference':'Profile_'+str(fileEN4)+'_'+str(prof),\n",
    "                                                        'file':fileEN4,'profile no':int(prof),\n",
    "                                                        'latitude':float(laten4),\n",
    "                                                        'longitude':float(lonen4),\n",
    "                                                        'date':str(dayen4),\n",
    "                                                        'i0':int(i0),'j0':int(j0)}}\n",
    "        dictyml.update(up)\n",
    "    else:\n",
    "        dictyml={'Profile_'+str(fileEN4)+'_'+str(prof):{'reference':'Profile_'+str(fileEN4)+'_'+str(prof),\n",
    "                                                        'file':fileEN4,'profile no':int(prof),\n",
    "                                                        'latitude':float(laten4),\n",
    "                                                        'longitude':float(lonen4),\n",
    "                                                        'date':str(dayen4),\n",
    "                                                        'i0':int(i0),'j0':int(j0)}}\n",
    "    return dictyml\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#loop on all the files\n",
    "\n",
    "# name of the json file in which selection of profiles informations will be stored\n",
    "jsonfile='txt/MEDWEST60-BLBT02_'+str(datemin)+'-'+str(datemax)+'_'+str(depthmin)+'m_'+str(radius_max)+'x'+str(period)+'d_'+str(number_of_model_profiles)+'.json'\n",
    "if not os.path.exists(jsonfile):\n",
    "    jdict={}\n",
    "    for f in range(len(list_filesEN4)):\n",
    "        fileEN4=list_filesEN4[f]\n",
    "        ds=xr.open_dataset(diren4+fileEN4)\n",
    "        nprof=len(ds.N_PROF)\n",
    "        for prof in range(nprof):\n",
    "            i0,j0=loc(fileEN4,prof)\n",
    "            if (i0,j0) == (-1,-1):\n",
    "                print('profile is not in the domain at all')\n",
    "                continue\n",
    "            check=check_prof_in_ocean(i0,j0)\n",
    "            if check == 1:\n",
    "                print('no, profile is on the land')\n",
    "                continue\n",
    "            print('yes, profile is in the ocean')\n",
    "            check=check_prof_depth(fileEN4,prof)\n",
    "            if check == 1:\n",
    "                print('no, profile is not deep enough')\n",
    "                continue\n",
    "            print('yes, profile is deep enough')\n",
    "            check_number_profile(fileEN4,prof,i0,j0)\n",
    "            print(check)\n",
    "            if check == 1:\n",
    "                print('no, there are not enough model profiles')\n",
    "                continue\n",
    "            print('yes, there are enough model profiles')\n",
    "            jdict=make_dict(fileEN4,prof,i0,j0,jdict)\n",
    "\n",
    "    #write dict in a json file           \n",
    "    with io.open(str(jsonfile), 'a+', encoding='utf8') as outfile:\n",
    "        outfile.write(str(json.dumps(jdict, sort_keys=True,indent=4, separators=(',', ': '))))\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
